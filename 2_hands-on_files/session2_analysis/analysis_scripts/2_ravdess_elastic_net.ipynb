{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5ff197a",
   "metadata": {},
   "source": [
    "# Elastic Net\n",
    "\n",
    "In this script, we will:\n",
    "1. Load and preprocess the dataset.\n",
    "2. Fit Elastic Net model.\n",
    "3. Visualize top features per emotion class.\n",
    "4. Identify features with zero coefficient value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7bf92a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a393d701",
   "metadata": {},
   "source": [
    "### Task 1: Load the CSV file\n",
    "Same as in script of correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1790734a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_mean</th>\n",
       "      <th>f0_stddev</th>\n",
       "      <th>f0_range</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_stddev</th>\n",
       "      <th>f1_range</th>\n",
       "      <th>f2_mean</th>\n",
       "      <th>f2_stddev</th>\n",
       "      <th>f2_range</th>\n",
       "      <th>f3_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>AU23_std</th>\n",
       "      <th>AU24_std</th>\n",
       "      <th>AU25_std</th>\n",
       "      <th>AU26_std</th>\n",
       "      <th>AU28_std</th>\n",
       "      <th>AU43_std</th>\n",
       "      <th>mouth_openness_std</th>\n",
       "      <th>condition</th>\n",
       "      <th>id</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>187.954488</td>\n",
       "      <td>71.416690</td>\n",
       "      <td>237.048375</td>\n",
       "      <td>922.823132</td>\n",
       "      <td>468.613940</td>\n",
       "      <td>1996.040116</td>\n",
       "      <td>1901.817187</td>\n",
       "      <td>625.338642</td>\n",
       "      <td>3267.843008</td>\n",
       "      <td>3056.335186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167865</td>\n",
       "      <td>0.027854</td>\n",
       "      <td>0.012677</td>\n",
       "      <td>0.105102</td>\n",
       "      <td>0.023936</td>\n",
       "      <td>0.137085</td>\n",
       "      <td>14.985116</td>\n",
       "      <td>happy</td>\n",
       "      <td>19</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125.649480</td>\n",
       "      <td>18.592790</td>\n",
       "      <td>76.282777</td>\n",
       "      <td>896.902975</td>\n",
       "      <td>451.287522</td>\n",
       "      <td>2158.738997</td>\n",
       "      <td>1955.646204</td>\n",
       "      <td>547.505858</td>\n",
       "      <td>2528.638337</td>\n",
       "      <td>2989.774860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117064</td>\n",
       "      <td>0.181223</td>\n",
       "      <td>0.440511</td>\n",
       "      <td>0.322437</td>\n",
       "      <td>0.173739</td>\n",
       "      <td>0.039355</td>\n",
       "      <td>6.956635</td>\n",
       "      <td>calm</td>\n",
       "      <td>15</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>196.733026</td>\n",
       "      <td>59.763476</td>\n",
       "      <td>234.624127</td>\n",
       "      <td>807.336950</td>\n",
       "      <td>404.598851</td>\n",
       "      <td>1968.301265</td>\n",
       "      <td>1875.814368</td>\n",
       "      <td>424.990421</td>\n",
       "      <td>2902.265406</td>\n",
       "      <td>2966.456851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075628</td>\n",
       "      <td>0.028787</td>\n",
       "      <td>0.025267</td>\n",
       "      <td>0.234712</td>\n",
       "      <td>0.030841</td>\n",
       "      <td>0.009683</td>\n",
       "      <td>9.751621</td>\n",
       "      <td>surprised</td>\n",
       "      <td>21</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>233.731870</td>\n",
       "      <td>24.199943</td>\n",
       "      <td>101.728680</td>\n",
       "      <td>917.300413</td>\n",
       "      <td>424.694396</td>\n",
       "      <td>2083.518310</td>\n",
       "      <td>1890.668478</td>\n",
       "      <td>357.316926</td>\n",
       "      <td>2384.954571</td>\n",
       "      <td>2916.709624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182716</td>\n",
       "      <td>0.018268</td>\n",
       "      <td>0.002271</td>\n",
       "      <td>0.071390</td>\n",
       "      <td>0.032285</td>\n",
       "      <td>0.164527</td>\n",
       "      <td>12.347607</td>\n",
       "      <td>happy</td>\n",
       "      <td>9</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>263.508762</td>\n",
       "      <td>92.190807</td>\n",
       "      <td>402.873141</td>\n",
       "      <td>916.405078</td>\n",
       "      <td>487.460380</td>\n",
       "      <td>1964.002644</td>\n",
       "      <td>1998.063510</td>\n",
       "      <td>561.750355</td>\n",
       "      <td>2774.517885</td>\n",
       "      <td>3087.675790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109795</td>\n",
       "      <td>0.119696</td>\n",
       "      <td>0.181175</td>\n",
       "      <td>0.200143</td>\n",
       "      <td>0.069560</td>\n",
       "      <td>0.369833</td>\n",
       "      <td>12.062537</td>\n",
       "      <td>disgust</td>\n",
       "      <td>19</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      f0_mean  f0_stddev    f0_range     f1_mean   f1_stddev     f1_range  \\\n",
       "0  187.954488  71.416690  237.048375  922.823132  468.613940  1996.040116   \n",
       "1  125.649480  18.592790   76.282777  896.902975  451.287522  2158.738997   \n",
       "2  196.733026  59.763476  234.624127  807.336950  404.598851  1968.301265   \n",
       "3  233.731870  24.199943  101.728680  917.300413  424.694396  2083.518310   \n",
       "4  263.508762  92.190807  402.873141  916.405078  487.460380  1964.002644   \n",
       "\n",
       "       f2_mean   f2_stddev     f2_range      f3_mean  ...  AU23_std  AU24_std  \\\n",
       "0  1901.817187  625.338642  3267.843008  3056.335186  ...  0.167865  0.027854   \n",
       "1  1955.646204  547.505858  2528.638337  2989.774860  ...  0.117064  0.181223   \n",
       "2  1875.814368  424.990421  2902.265406  2966.456851  ...  0.075628  0.028787   \n",
       "3  1890.668478  357.316926  2384.954571  2916.709624  ...  0.182716  0.018268   \n",
       "4  1998.063510  561.750355  2774.517885  3087.675790  ...  0.109795  0.119696   \n",
       "\n",
       "   AU25_std  AU26_std  AU28_std  AU43_std  mouth_openness_std  condition  id  \\\n",
       "0  0.012677  0.105102  0.023936  0.137085           14.985116      happy  19   \n",
       "1  0.440511  0.322437  0.173739  0.039355            6.956635       calm  15   \n",
       "2  0.025267  0.234712  0.030841  0.009683            9.751621  surprised  21   \n",
       "3  0.002271  0.071390  0.032285  0.164527           12.347607      happy   9   \n",
       "4  0.181175  0.200143  0.069560  0.369833           12.062537    disgust  19   \n",
       "\n",
       "    sex  \n",
       "0  male  \n",
       "1  male  \n",
       "2  male  \n",
       "3  male  \n",
       "4  male  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load CSV\n",
    "df = pd.read_csv(\"../ravdess_processed_data/combined_summary_updated.csv\") \n",
    "# Preview the dataset (first few rows)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a698e3",
   "metadata": {},
   "source": [
    "### Task 2: Create a function to preprocess the data\n",
    "\n",
    "Follow the steps:\n",
    "1. Drop metadata columns\n",
    "2. Separate features and target\n",
    "3. Encode target labels (sklearn - LabelEncoder)\n",
    "4. Split into train and test sets (sklearn - train_test_split)\n",
    "5. Impute missing values (sklearn - SimpleImputer)\n",
    "6. Scale features (sklearn - StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d0f67b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement a function for preprocessing\n",
    "def preprocess_data(df, target_col=\"condition\",test_size=0.2, random_state=42, metadata_cols=[\"id\", \"sex\"]):\n",
    "    \"\"\"\n",
    "        Preprocess the dataset for modeling:\n",
    "        - Drop metadata columns\n",
    "        - Separate features and target\n",
    "        - Encode target labels\n",
    "        - Split into train and test sets\n",
    "        - Impute missing values (fit on train, transform on test)\n",
    "        - Scale features (fit on train, transform on test)\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): Input dataset\n",
    "            target_col (str): Name of the target column\n",
    "            metadata_cols (list, optional): Columns to drop\n",
    "            test_size (float, optional): Proportion of the dataset to include in the test split\n",
    "            random_state (int, optional): Seed used by the random number generator\n",
    "\n",
    "        Returns:\n",
    "            X_train_scaled (np.ndarray): Scaled training feature matrix\n",
    "            X_test_scaled (np.ndarray): Scaled test feature matrix\n",
    "            y_train (np.ndarray): Encoded training target labels\n",
    "            y_test (np.ndarray): Encoded test target labels\n",
    "            feature_names (list): Names of the features\n",
    "            class_labels (np.ndarray): Original class labels\n",
    "    \"\"\"\n",
    "    return None, None, None, None, None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b2ab4c",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><span style=\"font-size:20px; color:darkgoldenrod; font-weight:bold;\">Click to see the solution</span></summary>\n",
    "\n",
    "```python\n",
    "def preprocess_data(df, target_col=\"condition\", metadata_cols=[\"id\", \"sex\"]):\n",
    "    \"\"\"\n",
    "    Preprocess the dataset for modeling - drop metadata columns, separate features and target, encode target labels, impute missing values, and scale features\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataset\n",
    "        target_col (str): Name of the target column\n",
    "        metadata_cols (list, optional): Columns to drop. Defaults to [\"id\"].\n",
    "\n",
    "    Returns:\n",
    "        X_scaled (np.ndarray): Scaled feature matrix\n",
    "        y_enc (np.ndarray): Encoded target labels\n",
    "        feature_names (list): Names of the features\n",
    "        class_labels (np.ndarray): Original class labels\n",
    "    \"\"\"\n",
    "    if metadata_cols is None:\n",
    "        metadata_cols = []\n",
    "\n",
    "    # Drop metadata columns \n",
    "    df = df.drop(columns=metadata_cols, errors=\"ignore\")\n",
    "\n",
    "    # Separate target and features\n",
    "    y = df[target_col]\n",
    "    X = df.drop(columns=[target_col])\n",
    "    feature_names = X.columns\n",
    "\n",
    "    # Encode target labels\n",
    "    label_enc = LabelEncoder()\n",
    "    y_enc = label_enc.fit_transform(y)\n",
    "    class_labels = label_enc.classes_\n",
    "\n",
    "    # Split into train and test (before scaling/imputation to avoid leakage)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_enc, test_size=test_size, random_state=random_state, stratify=y_enc\n",
    "    )\n",
    "\n",
    "    # Impute missing values (fit on training, transform both)\n",
    "    imputer = SimpleImputer(strategy=\"mean\")\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "    # Scale features (fit on training, transform both)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "    X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, feature_names, class_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db355c62",
   "metadata": {},
   "source": [
    "### Task 3: Elastic Net Logistic Regression\n",
    "\n",
    "🎯 Fit multinomial logistic regression with Elastic Net penalty (sklearn - LogosticRegression)\n",
    "\n",
    "Logistic Regression is suitable for classification tasks, including multinomial problems like predicting multiple categories\n",
    "\n",
    "Elastic Net combines L1 (Lasso) and L2 (Ridge) regularization: [original paper: https://academic.oup.com/jrsssb/article/67/2/301/7109482]\n",
    "1. L1 encourages sparsity, helping to select important features and ignore irrelevant ones.\n",
    "2. L2 shrinks coefficients to prevent overfitting and improve model generalization.\n",
    "\n",
    "⚠️ Important: Make sure to split the data into train and test sets, and use only the training set to identify feature importance—otherwise, you risk data leakage for the next classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "77ebb4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement a function to for elastic net logisitic regression\n",
    "def elasticnet_logreg(X_scaled, y_enc, feature_names, class_labels, l1_ratio=0.5, max_iter=5000):\n",
    "    \"\"\"\n",
    "    Fit multinomial logistic regression with Elastic Net and return coefficients\n",
    "\n",
    "    Args:\n",
    "        X_scaled (np.ndarray): Preprocessed features \n",
    "        y_enc (np.ndarray): Encoded target labels\n",
    "        feature_names (list): Names of the features\n",
    "        class_labels (np.ndarray): Original class labels\n",
    "        l1_ratio (float): Elastic Net mixing parameter\n",
    "        max_iter (int): Maximum iterations for convergence\n",
    "\n",
    "    Returns:\n",
    "        coef_df (pd.DataFrame): Feature coefficients (features x classes)\n",
    "    \"\"\"\n",
    "    return None\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6950bdb7",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><span style=\"font-size:20px; color:darkgoldenrod; font-weight:bold;\">Click to see the solution</span></summary>\n",
    "\n",
    "```python\n",
    "\n",
    "def elasticnet_logreg(X_scaled, y_enc, feature_names, class_labels, l1_ratio=0.5, max_iter=5000):\n",
    "    \"\"\"\n",
    "    Fit multinomial logistic regression with Elastic Net and return coefficients\n",
    "\n",
    "    Args:\n",
    "        X_scaled (np.ndarray): Preprocessed features \n",
    "        y_enc (np.ndarray): Encoded target labels\n",
    "        feature_names (list): Names of the features\n",
    "        class_labels (np.ndarray): Original class labels\n",
    "        l1_ratio (float): Elastic Net mixing parameter\n",
    "        max_iter (int): Maximum iterations for convergence\n",
    "\n",
    "    Returns:\n",
    "        coef_df (pd.DataFrame): Feature coefficients (features x classes)\n",
    "    \"\"\"\n",
    "    clf = LogisticRegression(\n",
    "        penalty=\"elasticnet\",\n",
    "        solver=\"saga\",\n",
    "        l1_ratio=l1_ratio,\n",
    "        max_iter=max_iter,\n",
    "        random_state=42,\n",
    "        multi_class=\"multinomial\"\n",
    "    )\n",
    "    clf.fit(X_scaled, y_enc)\n",
    "\n",
    "    coef_df = pd.DataFrame(clf.coef_.T, index=feature_names, columns=class_labels)\n",
    "    return coef_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71d9127",
   "metadata": {},
   "source": [
    "### Task 4: Plot Top Features\n",
    "\n",
    "Visualize the top N features (by absolute coefficient) per emotion class using a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb6fcbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coef_heatmap(coef_df, N=20, figsize=(10, 8), cmap=\"coolwarm\"):\n",
    "    \"\"\"\n",
    "    Plot a heatmap of the top N features (by absolute coefficient across classes).\n",
    "\n",
    "    Args:\n",
    "        coef_df (pd.DataFrame): Feature coefficients (features × classes)\n",
    "        dataset_name (str): Dataset name for title\n",
    "        N (int): Number of top features to display\n",
    "        figsize (tuple): Figure size\n",
    "        cmap (str): Colormap for heatmap\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Select top-N features overall\n",
    "        top_features = coef_df.abs().max(axis=1).nlargest(N).index\n",
    "        plot_df = coef_df.loc[top_features]\n",
    "\n",
    "        plt.figure(figsize=figsize)\n",
    "        sns.heatmap(\n",
    "            plot_df,\n",
    "            annot=True, fmt=\".2f\", cmap=cmap, center=0,\n",
    "            cbar_kws={\"label\": \"Coefficient\"}\n",
    "        )\n",
    "        plt.title(f\"Top {N} Features (Elastic Net Logistic Regression)\", fontsize=14)\n",
    "        plt.xlabel(\"Emotion Class\")\n",
    "        plt.ylabel(\"Feature\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"[Warning] Could not plot\")\n",
    "        print(\"Most likely the code is not yet complete (complete the cells with TODO).\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b31df42",
   "metadata": {},
   "source": [
    "### Task 5: Apply Model \n",
    "\n",
    "Fit model and plot top features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "90f88ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Could not plot\n",
      "Most likely the code is not yet complete (complete the cells with TODO).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled, y_train, y_test, feature_names, class_labels = preprocess_data(df)\n",
    "coefs = elasticnet_logreg(X_train_scaled, y_train, feature_names, class_labels, l1_ratio=0.5)\n",
    "\n",
    "plot_coef_heatmap(coefs, N=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49389545",
   "metadata": {},
   "source": [
    "### Insights?\n",
    "\n",
    "🔍 Which features have the largest absolute coefficients for each emotion? Do these make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186b7978",
   "metadata": {},
   "source": [
    "### Task 6: Identify features with zero coefficient value. \n",
    "\n",
    "Relevant for the next script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c5349ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most likely the code is not yet complete (complete the cells with TODO).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    elasticnet_abs = coefs.abs().max(axis=1)\n",
    "    elasticnet_dropped_features = elasticnet_abs[elasticnet_abs == 0].index.tolist()\n",
    "\n",
    "    print(\"features dropped :\", len(elasticnet_dropped_features), elasticnet_dropped_features)\n",
    "except Exception as e:\n",
    "    print(\"Most likely the code is not yet complete (complete the cells with TODO).\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404c54de",
   "metadata": {},
   "source": [
    "#### Bonus task\n",
    "🤔 Try experimenting with different l1_ratio values to see how it affects feature selection!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665607cb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
