{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63c238cd-a927-4201-82fc-e9365c245f92",
   "metadata": {},
   "source": [
    "# Extract Facial Expressivity Features\n",
    "\n",
    "In this script, we will extract facial expressivity features from a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5311d128-b331-4546-aa19-b37110d757fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-08 22:39:46.768658: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-08 22:39:46.806676: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-09-08 22:39:46.806713: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-08 22:39:46.807912: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-08 22:39:46.815435: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-08 22:39:47.514509: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1757363993.821351  693379 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1757363993.829271  693379 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1757363993.832172  693380 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Facial features extracted: output/RAVDESS/extracted_features/facial_expressivity.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Extract facial expressivity features from MP4\n",
    "\"\"\"\n",
    "\n",
    "import openwillis as ow\n",
    "\n",
    "def extract_facial_features(video_file, output_file):\n",
    "    \"\"\"Extract facial expressivity features from video file\"\"\"\n",
    "    try:\n",
    "        # Use OpenWillis to extract facial features\n",
    "        framewise_loc, framewise_disp, summary = ow.facial_expressivity(\n",
    "            baseline_filepath = '',    # '' = no baseline video available    \n",
    "            filepath=video_file,\n",
    "            bbox_list=[],              # Empty list = detect face automatically\n",
    "            base_bbox_list=[],         # Empty list = detect baseline face automatically\n",
    "            normalize=True,            \n",
    "            align=False,                \n",
    "            rolling_std_seconds=3,     \n",
    "            split_by_speaking=False    \n",
    "        )\n",
    "        \n",
    "        # Save the summary data to CSV\n",
    "        summary.to_csv(output_file, index=False)\n",
    "        \n",
    "        print(f\" Facial features extracted: {output_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting features from {video_file}: {e}\")\n",
    "\n",
    "# Define input and output files\n",
    "video_file = \"public_raw_data/RAVDESS_English_video_audio/Actor_01/01-01-01-01-01-01-01.mp4\"   # Input video file\n",
    "output_file = \"output/RAVDESS/extracted_features/facial_expressivity.csv\"                      # Output CSV file with features\n",
    "\n",
    "# Extract facial expressivity features\n",
    "extract_facial_features(video_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:openwillis_3.1]",
   "language": "python",
   "name": "conda-env-openwillis_3.1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
